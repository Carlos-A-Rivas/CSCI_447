{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import dataset\n",
    "\n",
    "print(\"testing...\")\n",
    "\n",
    "def make_plots(zero_one_list, f1_score_list, names_list):\n",
    "    f1_data = [f1_scores[i] for i in range(len(f1_scores))]\n",
    "    loss_data = [loss_scores[i] for i in range(len(loss_scores))]\n",
    "\n",
    "    positions = np.arange(len(f1_scores))\n",
    "    width = 0.4\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(f1_data, positions=positions, widths=width, patch_artist=True,\n",
    "                boxprops=dict(facecolor='lightblue'), medianprops=dict(color='blue'),\n",
    "                whiskerprops=dict(color='blue'), capprops=dict(color='blue'),\n",
    "                flierprops=dict(markerfacecolor='blue', marker='o'))\n",
    "    plt.xticks(positions, names_list)\n",
    "    plt.xlabel('Datasets')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Scores Across Datasets')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.boxplot(loss_data, positions=positions, widths=width, patch_artist=True,\n",
    "                boxprops=dict(facecolor='lightcoral'), medianprops=dict(color='red'),\n",
    "                whiskerprops=dict(color='red'), capprops=dict(color='red'),\n",
    "                flierprops=dict(markerfacecolor='red', marker='o'))\n",
    "    plt.xticks(positions, names_list)\n",
    "    plt.xlabel('Datasets')\n",
    "    plt.ylabel('0/1 Loss Score')\n",
    "    plt.title('0/1 Loss Scores Across Datasets')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class algorithm:\n",
    "    def __init__(self, data_array:dataset, which_data:str):\n",
    "        # The algorithm takes in a pre-processed dataset object, there shouldn't be much to do with the constructor except maybe a setter for the dataset\n",
    "        self.data_array = data_array\n",
    "\n",
    "        # Determines label type\n",
    "        cancer_labels = ['2','4']\n",
    "        glass_labels = ['1','2','3','4','5','6','7']\n",
    "        iris_labels = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "        soybean_labels = ['D1','D2','D3','D4']\n",
    "        votes_labels = ['republican','democrat']\n",
    "        if (which_data == 'cancer'):\n",
    "            self.labels = cancer_labels\n",
    "        elif (which_data == 'glass'):\n",
    "            self.labels = glass_labels\n",
    "        elif (which_data == 'iris'):\n",
    "            self.labels = iris_labels\n",
    "        elif (which_data == 'soybean'):\n",
    "            self.labels = soybean_labels\n",
    "        elif (which_data == 'votes'):\n",
    "            self.labels = votes_labels\n",
    "\n",
    "    def train(self):\n",
    "        # Runs Q(), Runs F().\n",
    "\n",
    "        # Q() calculates the class prior probabilities, this create be an array 10 * the # of classes in the datset (10 for each validation set).\n",
    "        self.class_counts = [0] * len(self.labels)\n",
    "        self.probs = [0] * len(self.labels)\n",
    "        self.example_count = 0\n",
    "        self.class_probs = []\n",
    "        for i in range(10):\n",
    "            self.rotated_data = self.data_array.partitions[i:] + self.data_array.partitions[:i]\n",
    "            self.rotated_data = self.rotated_data[:-1]\n",
    "            for partition in range(9):\n",
    "                for example in range(len(self.rotated_data[partition])):\n",
    "                    self.example_count += 1\n",
    "                    for label in range(len(self.labels)):\n",
    "                        if (self.rotated_data[partition][example][-1] == self.labels[label]):\n",
    "                            self.class_counts[label] += 1\n",
    "            for i, count in enumerate(self.class_counts):\n",
    "                self.probs[i] = count/(self.example_count)\n",
    "            self.class_probs.append(self.probs.copy())\n",
    "\n",
    "        # F() calculates the individual attribute probabilities for each class. This creates an array of 10 * # of classes * # of attributes * # of attribute possibilites.\n",
    "        \n",
    "\n",
    "        # Once everything is run we should have trained 10 models for this method call. We will probably want to store each of these models in an array containing the other 2 arrays produced from Q and F, meaning there will be a ~7D array :/\n",
    "        # We will also want to save each of the models for both validation purposes, and for the event processing fails downstream we won't have to re-train\n",
    "        return\n",
    "        \n",
    "    def validate(self):\n",
    "\n",
    "        fold_order = [9] + list(range(0, 9))  #sets the order for which partition is our validation set\n",
    "        self.answers = []\n",
    "        self.predictions = []\n",
    "        for i in range(10):  #goes through each model\n",
    "            test_fold_index = fold_order[i]\n",
    "            class_prob_index = fold_order[(i + 1) % 10]\n",
    "\n",
    "        \n",
    "            test_fold = self.data_array.partitions[test_fold_index]\n",
    "            class_probs = self.class_probs[class_prob_index]\n",
    "            attribute_probs = self.attribute_probs[class_prob_index]\n",
    "            \n",
    "            self.correct_preditions = 0\n",
    "            total_predictions = len(test_fold)\n",
    "\n",
    "            for example in test_fold:\n",
    "                features = example[:-1]\n",
    "                true_label = example[-1]\n",
    "                self.answers.append(true_label)\n",
    "                max_class_prob = -float('inf')\n",
    "                predicted_class = None\n",
    "\n",
    "                for label in range(len(self.labels)):\n",
    "                    class_prob = class_prob[label_index]\n",
    "\n",
    "                    for feature_index, feature_value in enumerate(features):\n",
    "                        feature_prob = attribute_probs[label_index][feature_index].get(feature_value, 1)\n",
    "                        class_prob *= feature_prob\n",
    "\n",
    "\n",
    "                    if class_prob > max_class_prob:\n",
    "                        max_class_prob = class_prob\n",
    "                        predicted_class = self.labels[label_index]\n",
    "\n",
    "                predicted_label = predicted_class\n",
    "                self.predictions.append(predicted_label)\n",
    "\n",
    "              \n",
    "\n",
    "                \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # This method runs the algorithm on the validation folds. We want to make sure we are running the proper model on the proper fold, so if you trained on folds 1-9, you would start the for loop at 10 and decrement (for example).\n",
    "        # This will produce 10 classified folds, where we will want to save the results from the classification.\n",
    "        return\n",
    "    def calculate_loss(self):\n",
    "        # This method will analyze the classification, and determine, TP, TN, FP, FN, F1 loss, 0/1 loss, etc.\n",
    "        self.zero_one_losses = []\n",
    "        self.f1_scores = []\n",
    "        fold_order = [9] + list(range(0, 9))\n",
    "        for fold_index in fold_order:\n",
    "            test_fold = self.data_array.partitions[fold_index]\n",
    "\n",
    "            true_positives = {label: 0 for label in self.labels}\n",
    "            false_positives = {label: 0 for label in self.labels}\n",
    "            false_negatives = {label: 0 for label in self.labels}\n",
    "            correct_predictions = 0\n",
    "            total_predictions = len(test_fold)\n",
    "\n",
    "\n",
    "            for i in range(total_predictions):\n",
    "                true_label = self.answers[i]\n",
    "                predicted_label = self.predictions[i]\n",
    "\n",
    "\n",
    "                if predicted_label == true_label:\n",
    "                    correct_predictions += 1\n",
    "\n",
    "                if predicted_label == true_label:\n",
    "                    true_positives[true_label] += 1\n",
    "                else:\n",
    "                    false_positives[predicted_label] += 1\n",
    "                    false_negatives[true_label] += 1\n",
    "                \n",
    "\n",
    "            loss = 1 - (correct_predictions / total_predictions)\n",
    "            self.zero_one_loss.append(loss)\n",
    "\n",
    "\n",
    "\n",
    "            f1_scores_per_class = []\n",
    "            for label in self.labels:\n",
    "                precision = true_positives[label] / (true_positives[label] + false_positives[label]) if (true_positives[label] + false_positives[label]) > 0 else 0\n",
    "                recall = true_positives[label] / (true_positives[label] + false_negatives[label]) if (true_positives[label] + false_negatives[label]) > 0 else 0\n",
    "                f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "                f1_scores_per_class.append(f1)\n",
    "            \n",
    "            average_f1 = sum(f1_scores_per_class) / len(self.labels)\n",
    "            self.f1_scores.append(average_f1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # These results need to be saved\n",
    "        # We will also want to create a box plot where the x-axis is the dataset we worked with (10 datasets), and y axis is a performance metric (whatever we want). For each dataset there will be 10 datapoints in the box, each point represents the performance of one of the folds.\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_nopre = dataset('/home/carlos/Machine_Learning_Practice/processed_data/cancer_nopre.csv', 'last', True)\n",
    "glass_nopre = dataset('/home/carlos/Machine_Learning_Practice/processed_data/glass_nopre.csv', 'last', True)\n",
    "votes_nopre = dataset('/home/carlos/Machine_Learning_Practice/processed_data/votes_nopre.csv', 'first', True)\n",
    "iris_nopre = dataset('/home/carlos/Machine_Learning_Practice/processed_data/iris_nopre.csv', 'last', True)\n",
    "soybean_nopre = dataset('/home/carlos/Machine_Learning_Practice/processed_data/soybean_nopre.csv', 'last', True)\n",
    "\n",
    "cancer_pre = dataset('/home/carlos/Machine_Learning_Practice/processed_data/cancer_pre.csv', 'last', True)\n",
    "glass_pre = dataset('/home/carlos/Machine_Learning_Practice/processed_data/glass_pre.csv', 'last', True)\n",
    "votes_pre = dataset('/home/carlos/Machine_Learning_Practice/processed_data/votes_pre.csv', 'first', True)\n",
    "iris_pre = dataset('/home/carlos/Machine_Learning_Practice/processed_data/iris_pre.csv', 'last', True)\n",
    "soybean_pre = dataset('/home/carlos/Machine_Learning_Practice/processed_data/soybean_pre.csv', 'last', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Probabilities: [[0.6507936507936508, 0.3492063492063492], [0.647339158061954, 0.3526608419380461], [0.6514830508474576, 0.3485169491525424], [0.653953118792213, 0.34604688120778704], [0.6525746980292435, 0.3474253019707565], [0.6535099337748345, 0.34649006622516554], [0.6537238873751136, 0.34627611262488645], [0.6554738724418836, 0.34452612755811646], [0.654892264217591, 0.34510773578240905], [0.6552217453505007, 0.3447782546494993]]\n",
      "Class Probabilities: [[0.653968253968254, 0.346031746031746], [0.653693407466243, 0.34630659253375695], [0.6546610169491526, 0.3453389830508475], [0.656336909018673, 0.34366309098132697], [0.6560712015257469, 0.343928798474253], [0.6572185430463576, 0.34278145695364237], [0.6566757493188011, 0.34332425068119893], [0.655076495132128, 0.34492350486787204], [0.6555987283645355, 0.3444012716354645], [0.6552217453505007, 0.3447782546494993]]\n"
     ]
    }
   ],
   "source": [
    "cancer_nopre_processing = algorithm(cancer_nopre, 'cancer')\n",
    "cancer_nopre_processing.train()\n",
    "print(f\"Class Probabilities: {cancer_nopre_processing.class_probs}\")\n",
    "cancer_pre_processing = algorithm(cancer_pre, 'cancer')\n",
    "cancer_pre_processing.train()\n",
    "print(f\"Class Probabilities: {cancer_pre_processing.class_probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_one_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
